<html>
<head>
  <title>Ceph Nautilus 全功能集群部署与 Dashboard 集成</title>
  <basefont face="JetBrains Mono NL" size="2" />
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="exporter-version" content="YXBJ Windows/605627 (zh-CN, DDL); Windows/10.0.0 (Win64); EDAMVersion=V2;"/>
  <style>
    body, td {
      font-family: JetBrains Mono NL;
      font-size: 10pt;
    }
  </style>
</head>
<body>
<a name="2320"/>

<div>
<span><div><div><div><div><div><div><div><div><font style="font-size: 14pt;"><span style="font-size: 14pt; color: rgb(45, 79, 201); font-weight: bold;">Ceph Nautilus全功能集群部署与Dashboard集成</span></font></div><div><br/></div><div><span style="font-weight: bold;">文档说明：</span></div><ul><li><div>Red Hat Ceph Storage 3.0基于上游社区Luminous版开发发布。</div></li><li><div><span style="font-weight: bold;">Red Hat Ceph Storage 4基于上游社区Nautilus版开发发布。</span></div></li><li><div>此次部署由于硬件资源限制将Ceph mon与osd共同部署于同一节点上，组成POC集群。</div></li><li><div>生产环境需按照最低硬件要求部署Ceph集群。</div></li><li><div><b>文档中使用的repo文件与部分配置文件均已上传至GitHub仓库中，可直接拉取使用！</b></div></li></ul><div><br/></div><div><b>文档目录：</b></div><ul><li><div>集群资源与用户说明</div></li><li><div>Ceph dashboard概述</div></li><li><div>Ceph集群部署方式说明</div></li><li><div>安装部署前准备</div></li><li><div>Ceph集群部署过程</div></li><li><div>Ceph集群状态确认与部分报错</div></li><li><div>Ceph dashboard部署</div></li><li><div>Ceph dashboard中集成radosgw</div></li><li><div>Ceph dashboard中集成iscsi-gateway</div></li><li><div>部署Grafana监控面板</div></li><li><div>部署Prometheus与node_exporter</div></li><li><div>启用Ceph prometheus exporter模块</div></li><li><div>配置Grafana与Prometheus对接</div></li><li><div>配置Grafana模板</div></li></ul><div><br/></div><div><span style="font-weight: bold;">集群资源与用户说明：</span></div></div><ul><li><div>集群各节点硬件资源与角色：</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image.png" type="image/png" data-filename="Image.png" width="577"/></div></div><div><br/></div><ul><li><div>版本说明：</div></li></ul><div>     1. OS版本：CentOS Linux release 7.7.1908 (Core)</div><div>     2. kernel版本：5.6.8-1.el7.elrepo.x86_64</div><div>     3. Ceph版本：Nautilus</div><div>     4. ceph-deploy版本：2.0.1</div><div>     5. Grafana版本：grafana-5.4.2-1.x86_64</div><div>     6. Prometheus版本：prometheus-2.14.0.linux-amd64</div><div>     7. node_exporter版本：node_exporter-0.18.1.linux-amd64</div><div><br/></div><ul><li><div>集群各节点用户角色：</div></li></ul><div>     1. cephadm：Ceph集群部署与管理用户，该用户已添加至sudo列表。</div><div>     2. root：系统管理员用户</div><div>     <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>       必须配置每个Ceph集群节点的完整域名，部署Ceph iscsi-gateway时将使用！</div><div>     </div><div><span style="font-weight: bold;">Ceph dashboard概述：</span></div><ul><li><div><span style="font-weight: bold;">Ceph的官方dashboard正式从Ceph Luminous版本开始，最初是一个简单的只读视图，可查看</span></div></li></ul><div><span style="font-weight: bold;">     Ceph集群的各种运行时信息与性能数据，而无需身份验证或任何管理功能。</span></div><ul><li><div>Ceph Nautilus版本后的dashboard可实现管理Ceph的功能，其来源于SUSE收购的的商业Ceph</div></li></ul><div>     管理软件openATTIC的功能移植。</div><ul><li><div>现在的Ceph dashboard后端代码使用<span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">CherryPy</span>框架与自定义REST API实现。</div></li><li><div>WebUI基于<span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">Angular/TypeScript</span>实现。</div></li></ul><div><br/></div><div>     参考链接：</div><div>     <a href="https://docs.ceph.com/docs/master/mgr/dashboard/">https://docs.ceph.com/docs/master/mgr/dashboard/</a></div><div>     </div><div><span style="font-weight: bold;">Ceph集群部署方式说明：</span></div><ul><li><div>Ceph部署方式：</div></li></ul><div>     1. 命令行安装、ceph-deploy工具安装、ceph-ansible playbook安装。</div><div>     2. <span style="font-weight: bold;">cephadm容器化安装（O版开发中），且默认安装dashboard。</span>   </div><ul><li><div>该文档使用ceph-deploy工具安装部署。</div></li><li><div>Red Hat Ceph Storage 4还可使用Cockpit web-based图形化工具部署。</div></li><li><div><span style="font-weight: bold;">Cockpit web-based图形化工具底层依然使用ceph-ansible playbook安装部署。</span></div></li></ul><div><br/></div><div><span style="color: rgb(0, 0, 255); font-weight: bold;">     </span>参考链接：</div><div>     <a href="https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/pdf/installation_guide/Red_Hat_Ceph_Storage-4-Installation_Guide-en-US.pdf">https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/pdf/</a></div><div>     <a href="https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/pdf/installation_guide/Red_Hat_Ceph_Storage-4-Installation_Guide-en-US.pdf">installation_guide/Red_Hat_Ceph_Storage-4-Installation_Guide-en-US.pdf</a>  </div><div><br/></div><div><span style="font-weight: bold;">安装部署前准备：</span></div><ul><li><div>关闭所有节点的firewall防火墙，生产环境中开启firewall所需放行的端口。</div></li></ul><div>     cephadm@ceph-{admin,node0,node1,node2}:</div><div>       $ sudo systemctl stop firewalld.service</div><div>       $ sudo systemctl disable firewalld.service</div><div><br/></div><ul><li><div>关闭所有节点的SELinux功能</div></li><li><div>所有节点安装epel软件源： </div></li></ul><div>     cephadm@ceph-{admin,node0,node1,node2}:</div><div>       $ sudo yum install -y \</div><div>         https://mirrors.cloud.tencent.com/epel/epel-release-latest-7.noarch.rpm </div><div><br/></div><ul><li><div>所有节点配置域名解析：</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [1].png" type="image/png" data-filename="Image.png" width="578"/></div><div>     <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>       1. 此处必须设置FQDN（完全合格域名），不能只是主机名，否者在启用iscsi-gateway时会</div><div>          出现错误。</div><div>       2. <span style="font-weight: bold;">Ceph dashboard中Prometheus、iscsi-target以及Ceph mgr中都需要FQDN，以确保各</span></div><div><span style="font-weight: bold;">          主机能相互解析。 </span></div><div><br/></div><ul><li><div>配置集群NTP：</div></li></ul><div>     1. <span style="font-weight: bold;">Ceph集群对时间变化非常敏感，超出设定阈值（默认为0.5s）时，集群进入HEALTH_WARN状态。</span></div><div>     2. 配置集群NTP服务器：</div><div>        cephadm@ceph-admin:</div><div>          $ sudo vim /etc/chrony.conf</div><div>          # 配置该节点为集群的上游NTP时间同步服务器</div><div>          # 该配置文件参考链接：</div><div>            <a href="https://github.com/Alberthua-Perl/summary-scripts/blob/master/chrony.conf">https://github.com/Alberthua-Perl/summary-scripts/blob/master/chrony.conf</a>  </div><div><br/></div><div>          $ sudo systemctl restart chronyd.service</div><div>          # 重启chrony时间同步服务，使配置生效。</div><div>          <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>            由于使用联网的方式设置上游NTP时间同步服务器将造成未连接外网时集群时间异常，因此</div><div>            配置本地的NTP时间服务器（ceph-admin节点）同步集群时间。</div><div><br/></div><div>     3. 配置集群其余各节点的NTP服务：</div><div>        cephadm@ceph-node{0,1,2}:</div><div>          $ sudo vim /etc/chrony.conf</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [2].png" type="image/png" data-filename="Image.png" width="459"/></div><div>        </div><div>          $ sudo systemctl restart chronyd.service</div></div><div>          $ chronyc sources -v</div><div>          # 查看上游NTP时间同步服务器</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [3].png" type="image/png" data-filename="Image.png" width="540"/>  </div><div><br/></div><ul><li><div>升级系统kernel：<span style="color: rgb(250, 122, 0); font-weight: bold;">非必须步骤</span></div></li></ul><div>     1. <span style="font-weight: bold;">Ceph iscsi-gateway需要kernel v4.16或更高，或RHEL 7.5/CentOS 7.5或更高版本支持。</span></div><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [4].png" type="image/png" data-filename="Image.png" width="577"/></div><div><br/></div><div>     2. <span style="font-weight: bold;">此次部署使用CentOS 7.7，可不升级系统kernel直接部署。</span></div><div>     3. 若需升级系统kernel，在集群所有节点执行以下步骤：</div><div>        cephadm@ceph-{admin,node0,node1,node2}:</div><div>          $ sudo rpm -import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</div><div>          # 将RPM GPG公钥导入RPM本地数据库</div><div>          $ sudo wget -O /etc/pki/rpm-gpg/RPM-GPG-KEY-elrepo.org \</div><div>            https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</div><div>          # 下载RPM GPG公钥至RPM GPG公钥目录中  </div><div>          $ sudo rpm -Uvh \</div><div>            http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm</div><div>          # 升级安装elrepo软件源</div><div>       </div><div>          $ sudo yum --disablerepo=&quot;*&quot; --enablerepo=elrepo-kernel list available</div><div>          # 启用elrepo-kernel软件源查看可用的kernel软件包</div><div>          <span style="font-weight: bold;">$ sudo yum --enablerepo=elrepo-kernel install -y kernel-lt kernel-lt-devel</span></div><div>          # 启用elrepo-kernel软件源安装kernel-lt软件包   </div><div><br/></div><div>          <span style="font-weight: bold;">$ sudo awk -F\' '$1==&quot;menuentry &quot; {print $2}' /boot/grub2/grub.cfg</span></div><div>          # 查看可引导的kernel条目</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [5].png" type="image/png" data-filename="Image.png" width="539"/></div><div><br/></div><div>          <span style="font-weight: bold;">$ sudo vim /etc/default/grub</span></div><div>            GRUB_DEFAULT=0</div><div>          # 设置最新的kernel为默认引导项</div><div>          $ sudo grub2-mkconfig -o /boot/grub2/grub.cfg</div><div>          # 重新生成GRUB引导项</div><div>          $ sudo reboot             </div><div>          # 重启系统，查看默认kernel选项。 </div><div><br/></div><div><span style="font-weight: bold;">Ceph集群部署过程：</span></div><ul><li><div>配置Ceph软件源：</div></li></ul><div>     在ceph-admin部署节点配置ceph-deploy工具的yum软件源。</div><div>     cephadm@ceph-admin:</div><div>       $ sudo vim /etc/yum.repos.d/ceph.repo</div><div>       # 该软件源配置文件参考链接：</div><div>         <a href="https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/ceph.repo">https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/</a></div><div>         <a href="https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/ceph.repo">ceph.repo</a></div><div><br/></div><ul><li><div>安装ceph-deploy工具：</div></li></ul><div>     1. 在ceph-adm部署节点安装ceph-deploy工具，并查看版本为2.0.1。</div><div>     2. 若不配置ceph-deploy软件源，默认也可下载ceph-deploy，但下载的是1.5版本，该版本</div><div>        有bug，需安装额外缺失的包才能正常使用。</div><div><br/></div><div>     cephadm@ceph-admin:</div><div>       $ sudo yum install -y python-setuptools</div><div>       $ sudo yum install -y ceph-deploy</div><div>       <span style="font-weight: bold;">$ ceph-deploy --version</span></div><div>       # 确认ceph-deploy版本</div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [6].png" type="image/png" data-filename="Image.png" width="563"/>   </div><div><br/></div><ul><li><div>配置SSH免密码登录：</div></li></ul><div>     1. 在ceph-admin部署节点上使用root用户实现SSH免密码登录其余节点。</div><div>     2. 必须使用root用户实现，否则部署过程将报错！</div><div>     root@ceph-admin:</div><div>       # ssh-keygen</div><div>       # for i in {0..2}; do ssh-copy-id root@ceph-node$i; done</div><div>       // 分发root用户的SSH公钥至Ceph集群各节点</div><div><br/></div><ul><li><div>Ceph集群部署：</div></li></ul><div>     1. 创建初始化目录：</div><div>        <span style="font-weight: bold;">ceph-deploy执行部署时将生成的文件保存于该目录下，切换至该目录中再进行部署。</span></div><div>        root@ceph-admin:</div><div>          # mkdir ~/ceph-deploy; cd ~/ceph-deploy</div><div><br/></div><div>     2. 准备部署默认名称为ceph的集群：</div><div>        root@ceph-admin:</div><div>          <span style="font-weight: bold;"># ceph-deploy new \</span></div><div><span style="font-weight: bold;">            </span><a href="http://ceph-node0.lab.example.com/" style="font-weight: bold;">ceph-node0.lab.example.com</a><span style="font-weight: bold;"> </span><a href="http://ceph-node1.lab.example.com/" style="font-weight: bold;">ceph-node1.lab.example.com</a><span style="font-weight: bold;"> </span><a href="http://ceph-node2.lab.example.com/" style="font-weight: bold;">ceph-node2.lab.example.com</a></div><div>          // 准备部署Ceph集群，并生成ceph.conf集群配置文件与ceph.mon.keyring文件。</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [7].png" type="image/png" data-filename="Image.png" width="539"/></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy new.JPG" type="image/jpeg" data-filename="ceph-deploy new.JPG" width="540"/></div><div><br/></div><div>        <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>          1. 指定Ceph公共网络与集群网络初始化Ceph集群：</div><div>             root@ceph-admin:</div><div>               <span style="font-weight: bold;"># ceph-deploy new \</span></div><div><span style="font-weight: bold;">                 --public-network 10.197.11.0/24 \</span></div><div><span style="font-weight: bold;">                 --cluster-network 172.25.250.0/24 \</span></div><div><span style="font-weight: bold;">                 </span><a href="http://ceph-node0.lab.example.com/" style="font-weight: bold;">ceph-node0.lab.example.com</a><span style="font-weight: bold;"> </span><a href="http://ceph-node1.lab.example.com/" style="font-weight: bold;">ceph-node1.lab.example.com</a><span style="font-weight: bold;"> </span><a href="http://ceph-node2.lab.example.com/" style="font-weight: bold;">ceph-node2.lab.example.com</a><span style="font-weight: bold;">  </span></div><div><br/></div><div>          2. 若在Ceph集群初始化过程中未指定公共网络与集群网络，可在部署完成后手动配置。</div><div>             root@ceph-admin:</div><div>               # vim /etc/ceph/ceph.conf</div><div>               // 配置Ceph集群的public network与cluster network </div><div>               <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [8].png" type="image/png" data-filename="Image.png" width="366"/></div><div><br/></div><div>               # for i in {0..2}; do \</div><div>                 <span style="font-weight: bold;">ceph-deploy --overwrite-conf config push ceph-node$i</span>; \</div><div>                 done</div><div>               // 推送新的集群配置文件/etc/ceph/ceph.conf至集群的所有节点中</div><div>               <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy --overwrite-conf config push.JPG" type="image/jpeg" data-filename="ceph-deploy --overwrite-conf config push.JPG" width="500"/></div><div>                  </div><div>             root@ceph-node{0,1,2}:            </div><div>               # systemctl restart ceph-mon.target</div><div>               # systemctl restart ceph-osd.target</div><div>               // 重启所有节点的Ceph mon与osd守护进程，使配置生效。</div><div><br/></div><div>     3. 安装Ceph软件包：</div><div>        a. 默认ceph-deploy会自动下载匹配版本的Ceph。</div><div>        b. 若要自定义安装版本，使用 <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">--release</span> 选项指定安装的Ceph版本以及使用 <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">--repo-url</span></div><div>           选项指定自动配置的Ceph软件源。</div><div>        c. 不指定 --repo-url 选项，ceph-deploy会自动配置成国外的Ceph软件源，国内访问慢，</div><div>           容易安装失败。</div><div><br/></div><div>        root@ceph-admin:</div><div>          <span style="font-weight: bold;"># ceph-deploy install \</span></div><div><span style="font-weight: bold;">            --release nautilus \</span></div><div><span style="font-weight: bold;">            --repo-url http://mirrors.163.com/ceph/rpm-nautilus/el7/ \</span></div><div><span style="font-weight: bold;">            --gpg-url http://mirrors.163.com/ceph/keys/release.asc \</span></div><div><span style="font-weight: bold;">            </span><a href="http://ceph-node0.lab.example.com/" style="font-weight: bold;">ceph-node0.lab.example.com</a><span style="font-weight: bold;"> </span><a href="http://ceph-node1.lab.example.com/" style="font-weight: bold;">ceph-node1.lab.example.com</a><span style="font-weight: bold;"> </span><a href="http://ceph-node2.lab.example.com/" style="font-weight: bold;">ceph-node2.lab.example.com</a><span style="font-weight: bold;"> </span></div><div>          // Ceph集群的各个节点上安装指定版本的Ceph软件包</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy install.JPG" type="image/jpeg" data-filename="ceph-deploy install.JPG" width="539"/></div></div><div><br/></div><div>     4. 创建Ceph mon：</div><div>        root@ceph-admin:</div><div>          <span style="font-weight: bold;"># ceph-deploy mon create-initial</span></div><div>          # ls -lh ~/ceph-deploy</div><div>          // 查看部署目录中新生成的文件</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph mon create-initial.JPG" type="image/jpeg" data-filename="ceph mon create-initial.JPG" width="539"/></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [9].png" type="image/png" data-filename="Image.png" width="539"/>  </div><div><br/></div><div>     5. 推送集群配置文件与client.admin key-ring文件： </div><div>        root@ceph-admin:</div><div>          <span style="font-weight: bold;"># ceph-deploy admin </span><span style="font-weight: bold;">ceph-node0 ceph-node1 ceph-node1</span></div><div>          // 推送集群配置文件ceph.conf与ceph.client.admin.keyring文件至远程节点中。</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy admin.JPG" type="image/jpeg" data-filename="ceph-deploy admin.JPG" width="540"/></div><div><br/></div><div>     6. 初始化并创建OSD：</div><div>        a. Nautilus版中Ceph OSD默认使用<span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">bluestore</span>作为后端存储驱动。</div><div>        b. <span style="font-weight: bold;">bluestore不再使用XFS文件系统与journal高速缓存，而直接与LVM块设备实施读写。</span></div><div><span style="font-weight: bold;">        </span><span style="font-weight: bold;"><img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [10].png" type="image/png" data-filename="Image.png" width="555"/></span></div><div><br/></div><div>        root@ceph-admin:</div><div>          <span style="font-weight: bold;"># ceph-deploy osd create --data /dev/vdb</span> <a href="http://ceph-node0.lab.exmaple.com/" style="font-weight: bold;">ceph-node0.lab.exmaple.com</a></div><div>          # ceph-deploy osd create --date /dev/vdc <a href="http://ceph-node0.lab.example.com/">ceph-node0.lab.example.com</a></div><div>          # ceph-deploy osd create --data /dev/vdb <a href="http://ceph-node0.lab.exmaple.com/">ceph-node1.lab.exmaple.com</a></div><div>          # ceph-deploy osd create --date /dev/vdc <a href="http://ceph-node0.lab.example.com/">ceph-node1.lab.example.com</a>       </div><div>          # ceph-deploy osd create --data /dev/vdb <a href="http://ceph-node0.lab.exmaple.com/">ceph-node2.lab.exmaple.com</a></div><div>          # ceph-deploy osd create --date /dev/vdc <a href="http://ceph-node0.lab.example.com/">ceph-node2.lab.example.com</a></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy osd create（1）.JPG" type="image/jpeg" data-filename="ceph-deploy osd create（1）.JPG" width="539"/></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy osd create（2）.JPG" type="image/jpeg" data-filename="ceph-deploy osd create（2）.JPG" width="539"/></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy osd create（3）.JPG" type="image/jpeg" data-filename="ceph-deploy osd create（3）.JPG" width="539"/></div><div><br/></div><div>     7. 创建Ceph mgr：</div><div>        root@ceph-admin:</div><div>          <span style="font-weight: bold;"># ceph-deploy mgr create </span><a href="http://ceph-node0.lab.exmaple.com/" style="font-weight: bold;">ceph-node0.lab.exmaple.com</a></div><div>          # ceph-deploy mgr create <a href="http://ceph-node0.lab.exmaple.com/" style="font-weight: bold;">ceph-node1.lab.exmaple.com</a></div><div>          # ceph-deploy mgr create <a href="http://ceph-node0.lab.exmaple.com/" style="font-weight: bold;">ceph-node2.lab.exmaple.com</a></div><div>          // 3个Ceph存储节点创建Ceph mgr</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy mgr create（1）.JPG" type="image/jpeg" data-filename="ceph-deploy mgr create（1）.JPG" width="539"/></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-deploy mgr create（2）.JPG" type="image/jpeg" data-filename="ceph-deploy mgr create（2）.JPG" width="539"/></div><div><br/></div><div>     8. 部署CephFS：</div><div>        <span style="font-weight: bold;">部署的CephFS不需要做其它集成工作，可直接在dashboard中显示。</span></div><div>        root@ceph-admin:</div><div>          # ceph-deploy mds create <a href="http://ceph-node0.lab.exmaple.com/" style="font-weight: bold;">ceph-node0.lab.exmaple.com</a></div><div>          # ceph-deploy mds create <a href="http://ceph-node0.lab.exmaple.com/" style="font-weight: bold;">ceph-node1.lab.exmaple.com</a></div><div>          # ceph-deploy mds create <a href="http://ceph-node0.lab.exmaple.com/" style="font-weight: bold;">ceph-node2.lab.exmaple.com</a></div><div>          // 3个Ceph存储节点创建Ceph mds服务器</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph部署mds cephfs.JPG" type="image/jpeg" data-filename="ceph部署mds cephfs.JPG" width="540"/></div><div><br/></div><div>        cephadm@ceph-node0：</div><div>          $ ceph osd pool create cephfs_data 32 32</div><div>          $ ceph osd pool create cephfs_metadata 32 32</div><div>          $ ceph osd pool application enable cephfs_data cephfs</div><div>          $ ceph osd pool application enable cephfs_metadata cephfs</div><div>          // 创建CephFS存储池，并启用cephfs应用类型。  </div><div><br/></div><div>          <span style="font-weight: bold;">$ ceph fs new cephfs cephfs_metadate cephfs_data</span></div><div>          // 创建cephfs文件系统           </div><div>          <span style="font-weight: bold;">$ ceph fs status</span></div><div><span style="font-weight: bold;">          $ ceph mds stat</span></div><div>          // 查看CephFS文件系统与Ceph mds状态</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [11].png" type="image/png" data-filename="Image.png" width="539"/>  </div><div><br/></div><div>     9. 部署Ceph radosgw：</div><div>        <span style="font-weight: bold;">Ceph radosgw作为Ceph集群的客户端，也作为外部客户端连接Ceph集群的中间层。</span></div><div>        root@ceph-admin:</div><div>          <span style="font-weight: bold;"># ceph-deploy install \</span></div><div><span style="font-weight: bold;">           </span> <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">--rgw</span> <span style="font-weight: bold;">\</span></div><div><span style="font-weight: bold;">            --release nautilus \</span></div><div><span style="font-weight: bold;">            --repo-url http://mirrors.163.com/ceph/rpm-nautilus/el7/ \</span></div><div><span style="font-weight: bold;">            --gpg-url http://mirrors.163.com/ceph/keys/release.asc \</span></div><div>            <a href="http://ceph-node0.lab.example.com/" style="font-weight: bold;">ceph-node0.lab.example.com</a><span style="font-weight: bold;"> </span><a href="http://ceph-node1.lab.example.com/" style="font-weight: bold;">ceph-node1.lab.example.com</a><span style="font-weight: bold;"> </span><a href="http://ceph-node2.lab.example.com/" style="font-weight: bold;">ceph-node2.lab.example.com</a> </div><div>          // 指定节点上只安装Ceph radosgw相关的软件包   </div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph部署rgw（1）.JPG" type="image/jpeg" data-filename="ceph部署rgw（1）.JPG" width="540"/></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph部署rgw（2）.JPG" type="image/jpeg" data-filename="ceph部署rgw（2）.JPG" width="540"/>  </div><div><br/></div><div>          <span style="font-weight: bold;"># ceph-deploy rgw create </span><a href="http://ceph-node0.lab.example.com/" style="font-weight: bold;">ceph-node0.lab.example.com</a></div><div>          # ceph-deploy rgw create <a href="http://ceph-node0.lab.example.com/">ceph-node1.lab.example.com</a></div><div>          # ceph-deploy rgw create <a href="http://ceph-node0.lab.example.com/">ceph-node2.lab.example.com</a></div><div>          // 3个Ceph存储节点部署为Ceph radosgw</div><div>          // <span style="font-weight: bold;">生产环境中，建议单独部署Ceph radosgw，并且前端可配置负载均衡与高可用。</span></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/创建rgw.JPG" type="image/jpeg" data-filename="创建rgw.JPG" width="538"/></div><div><br/></div><div>          <span style="font-weight: bold;"># curl -s</span> <a href="http://ceph-node0.lab.example.com:7480/" style="font-weight: bold;">http://ceph-node0.lab.example.com:7480</a> <span style="font-weight: bold;">| xmllint --format -</span>          </div><div>          // 验证Ceph radosgw部署成功</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [12].png" type="image/png" data-filename="Image.png" width="540"/></div><div><br/></div><div>    10. 部署Ceph iscsi-gateway与iSCSI initiator集成：</div><div>        a. 每一Ceph iscsi-gateway运行Linux IO目标内核子系统（Linux IO target kernel</div><div>           subsystem，<span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">LIO</span>），以提供iSCSI协议支持。</div><div><span style="font-weight: bold;">    </span><span style="font-weight: bold;">   </span> b. <span style="font-weight: bold;">LIO利用用户空间传递（TCMU）与Ceph的librbd库交互，将RBD镜像公开给iSCSI initiator。</span></div><div><span style="font-weight: bold;">    </span><span style="font-weight: bold;">   </span> c. 此次部署将Ceph iscsi-gateway一同部署于Ceph mon节点上，生产环境中需将其单独</div><div>           部署于独立的节点上。</div><div>           <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div><span style="font-weight: bold;">             </span>1. 从Ceph Luminous版本开始支持iSCSI。</div><div>             2. Ceph中实现iSCSI方式有两种：</div><div>                a. 通过Linux target framework（tgt）实现</div><div>                b. <span style="font-weight: bold;">通过Linux IO target（LIO）实现，LIO也是官方推荐的方式。 </span></div><div><br/></div><div>        d. Ceph iscsi-gateway架构示意：</div><div>           <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Ceph iSCSI gateway (1).JPG" type="image/jpeg" data-filename="Ceph iSCSI gateway (1).JPG" width="530"/> </div><div><br/></div><div>        <span style="color: rgb(0, 0, 255); font-weight: bold;">* </span><span style="color: rgb(0, 0, 255); font-weight: bold;">部署Ceph iscsi-gateway：</span></div><div>        cephadm@ceph-node{0,1,2}:</div><div>          $ sudo vim /etc/yum.repos.d/ceph-iscsi.repo</div><div>          # 该软件源配置文件参考链接：</div><div>            <a href="https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/ceph-iscsi.repo">https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/</a></div><div>            <a href="https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/ceph-iscsi.repo">ceph-iscsi.repo</a>  </div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-iscsi.repo.png" type="image/png" data-filename="ceph-iscsi.repo.png" width="539"/></div><div>         </div><div>          $ sudo yum install -y ceph-iscsi</div><div>          # 在各个网关节点上安装ceph-iscsi软件包</div><div>          # <span style="font-weight: bold;">安装ceph-iscsi软件包时会自动安装tcmu-runner软件包</span></div><div><br/></div><div>          <span style="font-weight: bold;">$ sudo systemctl enable tcmu-runner.service</span></div><div>          $ sudo systemctl start tcmu-runner.service</div><div>          $ sudo systemctl status tcmu-runner.service</div><div>          # 启动tcmu-runner服务，并设置开机自启动。</div><div><br/></div><div>        cephadm@ceph-node0: <span style="color: rgb(250, 122, 0); font-weight: bold;">以下3步可选</span></div><div>          $ ceph osd pool create iscsi-images 32 32</div><div>          $ ceph osd pool application enable iscsi-images rbd</div><div>          $ rbd create --pool iscsi-images --size=2048M iscsi-gateway-image1</div><div>          # 创建RBD镜像存储池，并创建RBD镜像。     </div><div><br/></div><div>        cephadm@ceph-node{0,1,2}:</div><div>          $ sudo vim <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">/etc/ceph/iscsi-gateway.cfg</span></div><div>          # 配置Ceph iscsi-gateway配置文件</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/iscsi-gateway.png" type="image/png" data-filename="iscsi-gateway.png" width="538"/></div><div>            </div><div>          <span style="font-weight: bold;">$ sudo systemctl enable rbd-target-api.service</span></div><div>          $ sudo systemctl start rbd-target-api.service</div><div>          $ sudo systemctl status rbd-target-api.service</div><div>          # 启动rbd-target-api服务，并设置开机自启动，该服务监听5000端口。</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/12 查看iscsi gateway的守护进程.JPG" type="image/jpeg" data-filename="12 查看iscsi gateway的守护进程.JPG" width="539"/></div><div><br/></div><div>        cephadm@ceph-node0:     </div><div>          <span style="font-weight: bold;">$ sudo gwcli info</span></div><div>          # 查看网关服务状态</div><div>          <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>            1. iscsi-gateway命令行工具 <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">gwcli </span>用于创建、配置iscsi-target与rbd image。</div><div>            2. 其余较低级别命令行工具，如targetcli或rbd等，可用于查询配置，但不能用于修改</div><div>               gwcli所做的配置。</div><div>            3. 查看当前iscsi-gateway配置：</div><div>               a. gwcli命令行工具</div><div>               b. 配置了Ceph dashboard集成iscsi-gateway后，可使用Web图形界面配置。</div><div><br/></div><div>          <span style="color: rgb(250, 122, 0); font-weight: bold;">$ ceph dashboard set-iscsi-api-ssl-verification false</span></div><div>          # Ceph dashboard集成iscsi-gateway禁用iSCSI API SSL验证</div><div><br/></div><div>          <span style="font-weight: bold;">$ ceph dashboard iscsi-gateway-add http://admin:admin@10.197.11.188:5000</span></div><div>          $ ceph dashboard iscsi-gateway-add http://admin:admin@10.197.11.195:5000</div><div>          $ ceph dashboard iscsi-gateway-add http://admin:admin@10.197.11.193:5000</div><div>          # Ceph dashboard集成多个Ceph iscsi-gateway</div><div>          # 添加Ceph iscsi-gateway的用户名与密码为配置文件中定义的api_user与api_password</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph dashboard集成iscsi网关.JPG" type="image/jpeg" data-filename="ceph dashboard集成iscsi网关.JPG" width="539"/></div><div>     </div><div>          <span style="font-weight: bold;">$ ceph dashboard iscsi-gateway-list | jq .</span></div><div>          # 查看各个网关节点状态信息</div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/查看iscsi网关.JPG" type="image/jpeg" data-filename="查看iscsi网关.JPG" width="539"/></div><div>          <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/11 dashboard查看iscsi gateway.JPG" type="image/jpeg" data-filename="11 dashboard查看iscsi gateway.JPG" width="539"/>                 </div><div><br/></div><div>        <span style="color: rgb(0, 0, 255); font-weight: bold;">* 创建iSCSI target与iSCSI initiator集成：</span></div><div>          1. 在任一网关节点上查看iscsi target信息，并创建iscsi target。</div><div>             <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span>可通过gwcli命令行工具或Ceph dashboard图形化界面创建iscsi target。     </div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/1 创建iscsi target.JPG" type="image/jpeg" data-filename="1 创建iscsi target.JPG" width="516"/></div><div><br/></div><div>          2. 创建iscsi target对应的3个iscsi-gateway网关节点</div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/2 创建target对应的iscsi gateway.JPG" type="image/jpeg" data-filename="2 创建target对应的iscsi gateway.JPG" width="516"/></div><div>    </div><div>          3. iscsi-gateway网关节点上通过gwcli命令行创建RBD镜像</div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/3 通过iscsi gateway创建RBD镜像.JPG" type="image/jpeg" data-filename="3 通过iscsi gateway创建RBD镜像.JPG" width="517"/></div><div>        </div><div>          4. 创建可读写访问该iscsi-target的iscsi客户端主机</div><div>          5. 为iscsi客户端主机创建登录iscsi-target过程中认证的用户名与密码</div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/4 创建该target对应的客户端主机并创建客户端认证.JPG" type="image/jpeg" data-filename="4 创建该target对应的客户端主机并创建客户端认证.JPG" width="517"/>     </div><div><br/></div><div>          6. 添加新创建的RBD镜像至iscsi客户端主机上，实现RBD镜像的映射。</div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/5 创建客户端主机认证 为客户端添加磁盘.JPG" type="image/jpeg" data-filename="5 创建客户端主机认证 为客户端添加磁盘.JPG" width="517"/>     </div><div><br/></div><div>          7. 查看创建的iscsi-target与iscsi客户端主机的信息</div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/6 iscsi gateway创建完成.JPG" type="image/jpeg" data-filename="6 iscsi gateway创建完成.JPG" width="517"/></div><div><br/></div><div>          8. iscsi客户端安装多路径软件包，启动并配置多路径。</div><div>             $ sudo yum install -y device-mapper-multipath</div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/7 配置客户端多路径.JPG" type="image/jpeg" data-filename="7 配置客户端多路径.JPG" width="516"/></div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [13].png" type="image/png" data-filename="Image.png" width="515"/></div><div>     </div><div>          9. 更改iscsi客户端 <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">/etc/iscsi/iscsid.conf </span>配置文件中的认证方式、用户名与密码</div><div>             以发现与登录iscsi-target。</div><div>             <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/10 更改iscsid.conf认证方式 用户名与密码.JPG" type="image/jpeg" data-filename="10 更改iscsid.conf认证方式 用户名与密码.JPG" width="515"/></div><div>     </div><div>        10. 使用 <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">iscsiadm </span>命令发现与登录iscsi-target（3个iscsi-gateway网关节点），每个</div><div>            iscsi-target对应一条冗余链路以实现高可用。</div><div>        11. iscsi客户端可正常使用该映射的磁盘。</div><div>            <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/9 更改客户端iscsi认证用户名与密码 发现并登陆iscsi target.JPG" type="image/jpeg" data-filename="9 更改客户端iscsi认证用户名与密码 发现并登陆iscsi target.JPG" width="524"/></div><div>            <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [14].png" type="image/png" data-filename="Image.png" width="524"/></div><div>            <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [15].png" type="image/png" data-filename="Image.png" width="524"/> </div><div><br/></div><div>            参考链接：     </div><div>            <a href="https://ceph.io/planet/ceph%E7%9A%84iscsi-gateway/">https://ceph.io/planet/ceph%E7%9A%84iscsi-gateway/</a> </div><div><br/></div><div><span style="font-weight: bold;">Ceph集群状态确认与部分报错：</span></div><ul><li><div>Ceph集群部署已完成，查看集群状态。</div></li></ul><div>     cephadm@ceph-admin:</div><div>       <span style="font-weight: bold;">$ ceph -s</span></div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Ceph存储集群全功能集成 集群状态.JPG" type="image/jpeg" data-filename="Ceph存储集群全功能集成 集群状态.JPG" width="563"/></div><div>       </div><ul><li><div>Ceph集群默认在一天中任意时刻都可进行清理（<span style="font-weight: bold; font-style: italic; color: rgb(229, 0, 255);">scrube</span>）与深度清理（<span style="font-weight: bold; font-style: italic; color: rgb(229, 0, 255);">deep-scrube</span>），这将</div></li></ul><div>     造成集群网络负载升高，并进入HEALTH_WARN状态。</div><ul><li><div>使用 <span style="font-weight: bold; font-style: italic; color: rgb(0, 0, 255);">ceph -w</span> 查看集群实时状态。</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph -w监控集群级别数据清理与深度清理.JPG" type="image/jpeg" data-filename="ceph -w监控集群级别数据清理与深度清理.JPG" width="577"/></div><div><br/></div><ul><li><div>此次部署使用VMware虚拟机实现，性能状态不佳，显示慢操作（slow ops）警告。</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Ceph存储集群报错 slow ops.JPG" type="image/jpeg" data-filename="Ceph存储集群报错 slow ops.JPG" width="577"/></div><div><br/></div><div><span style="font-weight: bold;">Ceph dashboard部署：</span></div><ul><li><div>Ceph mgr部署完成，但未安装dashboard模块（插件）。</div></li></ul><div>     cephadm@ceph-node{0,1,2}:</div><div>       $ sudo yum install -y ceph-mgr-dashboard</div><div>       # 安装Ceph dashboard模块</div><div><br/></div><div>     cephadm@ceph-node0:</div><div>       <span style="font-weight: bold;">$ ceph mgr module enable dashboard</span></div><div>       # 启用Ceph dashboard模块</div><div>       <span style="font-weight: bold;"><font style="color: rgb(250, 122, 0);">$ ceph config set mgr mgr/dashboard/ssl false</font></span></div><div>       # 禁用dashboard模块的SSL功能 </div><div>       <span style="font-weight: bold;">$ ceph config set mgr mgr/dashboard/server_addr 0.0.0.0</span></div><div>       # 配置dashboard模块的监听地址，包括IPv4与IPv6地址。</div><div>       <span style="font-weight: bold;">$ ceph config set mgr mgr/dashboard/server_port 8443</span></div><div>       # 配置dashboard模块的监听端口  </div><div>           </div><div>       <span style="font-weight: bold;">$ ceph dashboard ac-user-create admin redhat administrator</span></div><div>       # 创建登录dashboard的用户名、密码及角色 </div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/创建dashboard管理员用户.JPG" type="image/jpeg" data-filename="创建dashboard管理员用户.JPG" width="563"/> </div><div><br/></div><div>       $ ceph mgr module disable dashboard</div><div>       $ ceph mgr module enable dashboard</div><div>       # 重新启用Ceph dashboard模块使配置生效   </div><div>        </div><div>       <span style="font-weight: bold;">$ ceph mgr services</span></div><div>       # 查看已开启的模块信息</div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [16].png" type="image/png" data-filename="Image.png" width="482"/> </div><div><br/></div><div>       访问URL <a href="http://ceph-node1.lab.example.com:8443/">http://ceph-node1.lab.example.com:8443</a> 以使用admin用户登录dashboard。</div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [17].png" type="image/png" data-filename="Image.png" width="563"/> </div><div><br/></div><div>       <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>         1. Ceph dashboard已部署完成，但radosgw、iscsi-gateway、监控等功能都需要逐个</div><div>            手动启用。</div><div>         2. radosgw未与dashboard集成：</div><div>            <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/rgw未启用.JPG" type="image/jpeg" data-filename="rgw未启用.JPG" width="524"/></div><div>         3. iscsi-gateway未与dashboard集成：</div><div>            <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/iscsi未启用.JPG" type="image/jpeg" data-filename="iscsi未启用.JPG" width="523"/></div><div>         4. NFS（nfs-ganesha）未与dashboard集成：         </div><div>            <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/nfs未启用.JPG" type="image/jpeg" data-filename="nfs未启用.JPG" width="524"/></div><div>         5. 监控未与dashboard集成：         </div><div>            <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/监控未启用.JPG" type="image/jpeg" data-filename="监控未启用.JPG" width="524"/></div><div><br/></div><div><span style="font-weight: bold;">Ceph dashboard中集成radosgw：</span></div><ul><li><div>Ceph dashboard默认安装好后，没有启用radosgw，需要手动在dashboard中启用radosgw。</div></li></ul><div>     cephadm@ceph-node0:</div><div>       <span style="font-weight: bold;">$ radosgw-admin user create --uid=rgw --display-name=rgw</span> <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">--system</span></div><div>       # 创建radosgw系统用户</div><div>       $ radosgw-admin user info --uid=rgw</div><div>       # 查看radosgw用户详细信息 </div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/创建rgw用户.JPG" type="image/jpeg" data-filename="创建rgw用户.JPG" width="563"/> </div><div>         </div><div>       <b>$ ceph dashboard set-rgw-api-access-key &lt;<span style="font-style: italic;">access_key</span>&gt;</b></div><div><b>       $ ceph dashboard set-rgw-api-secret-key &lt;<span style="font-style: italic;">secret_key</span>&gt;</b> </div><div>       # 设置dashboard访问radosgw的access key与secret key</div><div><br/></div><div>       <span style="font-weight: bold;"><font style="color: rgb(250, 122, 0);">$ ceph dashboard set-rgw-api-ssl-verify false</font></span></div><div>       # Ceph dashboard集成radosgw禁用SSL验证</div><div>       # 查看Ceph dashboard的显示，dashboard与radosgw集成完成。</div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [18].png" type="image/png" data-filename="Image.png" width="562"/></div><div><br/></div><div><span style="font-weight: bold;">Ceph dashboard中集成iscsi-gateway：</span></div><ul><li><div>前文已进行说明，此处不再说明。</div></li></ul><div><br/></div><div><span style="font-weight: bold;">部署Grafana监控面板：</span></div><ul><li><div>Ceph dashboard中集成了 <b><i><font style="color: rgb(0, 0, 255);">Grafana</font></i></b> 与 <b><i><font style="color: rgb(0, 0, 255);">Prometheus</font></i></b>，但需要手动启用。</div></li><li><div>Prometheus需要有exporter，并且Ceph mgr模块中内置了 prometheus exporter 模块，</div></li></ul><div>     因此无需要手动单独安装exporter。</div><ul><li><div>由于Ceph dashboard中Grafana还监控了Ceph存储节点的监控信息，因此每台存储节点中</div></li></ul><div>     需要安装 <b><i><font style="color: rgb(0, 0, 255);">Prometheus node exporter</font></i></b>。</div><div><br/></div><ul><li><div><span style="font-weight: bold;">Ceph dashboard、Prometheus与Grafana的架构关系：</span></div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/dashboard_architecture_481890_1118.png" type="image/png" data-filename="dashboard_architecture_481890_1118.png" width="577"/></div><div>     参考链接：Red Hat Ceph Storage 4监控架构概述</div><div>     <a href="https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/html-single/dashboard_guide/index">https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/html-single/</a></div><div>     <a href="https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/4/html-single/dashboard_guide/index">dashboard_guide/index</a></div><div><br/></div><div>     cephadm@ceph-admin:</div><div>       $ sudo vim /etc/yum.repos.d/grafana.repo</div><div>       # 该软件源配置文件参考链接：</div><div>         <a href="https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/grafana.repo">https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/</a></div><div>         <a href="https://github.com/Alberthua-Perl/summary-scripts/blob/master/yum-repo/grafana.repo">grafana.repo</a></div><div><br/></div><div>       $ sudo yum install -y grafana </div><div>      <b> $ sudo vim /etc/grafana/grafana.ini</b></div><div>       # 安装Grafana，并配置Grafana以与Ceph dashboard集成。</div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/更改grafana主题兼容ceph dashboard.JPG" type="image/jpeg" data-filename="更改grafana主题兼容ceph dashboard.JPG" width="562"/></div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/更改grafana匿名用户与ceph dashboard对接.JPG" type="image/jpeg" data-filename="更改grafana匿名用户与ceph dashboard对接.JPG" width="562"/> </div><div>       <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>         1. 需修改Grafana的默认暗黑风格（dark），更改为 <i><b><font style="color: rgb(0, 0, 255);">light</font></b></i>，否则无法集成到dashboard</div><div><span>    </span><span>    </span><span>    </span>中，两者风格不匹配！</div><div>         2. 启用Grafana的匿名验证模式，以与Ceph dashboard集成。</div><div>         3. 在较新版本的Grafana（从<b><i><font style="color: rgb(0, 0, 255);">6.2.0-beta1</font></i></b>开始）中，引入了一个名为 <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">allow_embedding</span> </div><div>            的新设置，需将其显示设置为 true，Ceph dashboard中的Grafana集成才能正常使用，</div><div>            其默认值为 false。</div><div><br/></div><div>       $ sudo systemctl enable grafana-server.service</div><div>       $ sudo systemctl start grafana-server.service</div><div>       $ sudo systemctl status grafana-server.service</div><div>       # 启动Grafana服务，并设置开机自启动。</div><div><br/></div><div>       <b>$ sudo grafana-cli plugins install vonage-status-panel</b></div><div><b>       $ sudo grafana-cli plugins install grafana-piechart-panel</b></div><div>       # 安装Grafana插件（需连接外部网络）</div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/安装grafana插件.JPG" type="image/jpeg" data-filename="安装grafana插件.JPG" width="561"/> </div><div><br/></div><div>       $ sudo systemctl restart grafana-server.service</div><div>       # 重启Grafana服务，使配置与插件生效。</div><div><br/></div><div>       访问URL <a href="http://ceph-admin.lab.example.com:3000/">http://ceph-admin.lab.example.com:3000</a>，输入默认用户名与密码，登录界面。</div><div>       查看已安装的插件。 </div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/grafana监听端口.JPG" type="image/jpeg" data-filename="grafana监听端口.JPG" width="562"/> </div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [19].png" type="image/png" data-filename="Image.png" width="563"/></div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [20].png" type="image/png" data-filename="Image.png" width="562"/> </div><div>         </div><div><span style="font-weight: bold;">部署Prometheus与node_exporter：</span></div><ul><li><div>从Prometheus官网或GitHub release中下载相应的软件包。</div></li></ul><div>     cephadm@ceph-admin:</div><div>       $ sudo tar -zxf prometheus-2.14.0.linux-amd64.tar.gz</div><div>       $ sudo mkdir /etc/prometheus </div><div>       $ sudo mv /root/prometheus-2.14.0.linux-amd64.tar.gz/* /etc/prometheus </div><div>       <b>$ sudo /etc/prometheus/prometheus --version</b></div><div>       # 查看Prometheus版本  </div></div><div><br/></div><div>       <span style="font-weight: bold;">$ sudo vim /etc/systemd/system/prometheus.service</span></div><div>         [Unit]</div><div>         Description=Prometheus Monitoring System</div><div>         Documentation=Prometheus Monitoring System</div><div><br/></div><div>         [Service]</div><div>         ExecStart=<b>/etc/prometheus/prometheus \</b></div><div><b>                   --config.file /etc/prometheus/prometheus.yml \</b></div><div><b>                   --web.listen-address=:9090</b></div><div><br/></div><div>         [Install]</div><div>         WantedBy=multi-user.target</div><div>         # 配置由systemd接管的Prometheus系统单元文件</div><div><br/></div><div>       <b>$ sudo vim /etc/prometheus/prometheus.yml</b></div><div>       # 配置Prometheus自定义配置文件</div><div>       # 该配置文件的参考链接：</div><div>         <a href="https://github.com/Alberthua-Perl/summary-scripts/blob/master/prometheus.yml">https://github.com/Alberthua-Perl/summary-scripts/blob/master/prometheus.yml</a></div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/prometheus config.png" type="image/png" data-filename="prometheus config.png" width="562"/>   </div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [21].png" type="image/png" data-filename="Image.png" width="563"/> </div><div>       <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>         1. 以上配置文件targetes需要写成域名，否者Ceph dashboard中host details中不能</div><div>            正常显示监控数据，而Grafana中显示正常。</div><div>         2. <span style="font-weight: bold;">Grafana使用IP查询，Ceph dashboard使用域名查询监控信息，而Prometheus中写的</span></div><div><span style="font-weight: bold;">            是IP，导致查询不到，所以这里要写成域名。</span></div><div>         3. <span style="color: rgb(0, 0, 255); font-style: italic; font-weight: bold;">honor_labels</span> 参数必须有并设置为true，否者会导致Ceph dashbaord中显示Grafana</div><div>            某些面板没有数据出现。 </div><div><br/></div><div>       $ sudo systemctl daemon-reload</div><div>       # 加载Prometheus系统单元文件</div><div><br/></div><div>       $ sudo systemctl enable prometheus.service</div><div>       $ sudo systemctl start prometheus.service</div><div>       $ sudo systemctl status prometheus.service</div><div>       # 启动Prometheus服务，并设置开机自启动。</div><div><br/></div><div>     cephadm@ceph-node{0,1,2}:</div><div>       $ sudo tar -zxf node_exporter-0.18.1.linux-amd64.tar.gz</div><div>       $ sudo mkdir /etc/node_exporter</div><div>       $ sudo mv /root/node_exporter-0.18.1.linux-amd64/* /etc/node_exporter</div><div><br/></div><div>       <span style="font-weight: bold;">$ sudo vim /etc/systemd/system/node_exporter.service</span></div><div>         [Unit]</div><div>         Description=Prometheus node_exporter</div><div><br/></div><div>         [Service]</div><div>         User=nobody</div><div>         ExecStart=<b>/etc/node_exporter/node_exporter --log.level=error</b></div><div>         ExecStop=/usr/bin/killall node_exporter</div><div>         # 配置由systemd接管的node_exporter单元文件</div><div><br/></div><div>       $ sudo systemctl daemon-reload</div><div>       $ sudo systemctl enable node_exporter.service</div><div>       $ sudo systemctl start node_exporter.service</div><div>       $ sudo systemctl status node_exporter.service</div><div>       # 加载node_exporter系统单元文件，启动该服务并设置开机自启动。</div><div><br/></div><div>       $ sudo netstat -tunlp | grep node_exporter</div><div>       # 查看各个Ceph集群节点node_exporter监控的端口（默认为9100端口）                   </div><div><br/></div><div><span style="font-weight: bold;">启用Ceph prometheus exporter模块：</span></div><ul><li><div>Ceph mgr附带Ceph prometheus exporter模块（插件），可手动启用该模块。</div></li></ul><div>     cephadm@ceph-node0:</div><div>       $ ceph mgr module ls</div><div>       # 查看Ceph mgr支持的附带模块列表 </div><div>       <span style="font-weight: bold;">$ ceph mgr module enable prometheus</span></div><div><span style="font-weight: bold;">       $ ceph mgr services</span></div><div>       # 启用Prometheus exporter模块，并查看已启用的模块信息。</div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [22].png" type="image/png" data-filename="Image.png" width="563"/></div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [23].png" type="image/png" data-filename="Image.png" width="564"/></div><div><br/></div><div>       访问URL <a href="http://ceph-admin.lab.example.com:9090/">http://ceph-admin.lab.example.com:9090</a> 查看Prometheus原生Web界面，确认</div><div>       targets状态。</div><div>       <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [24].png" type="image/png" data-filename="Image.png" width="562"/>  </div><div>       <span style="color: rgb(0, 0, 255); font-weight: bold;">* 注意：</span></div><div>         Prometheus部署完成后，依然存在2个报错（状态为Down），需排查解决！ </div><div><br/></div><div><span style="font-weight: bold;">     </span> <span style="font-weight: bold;"><font style="color: rgb(250, 122, 0);">$ ceph dashboard set-grafana-api-ssl-verify false</font></span></div><div>      # Ceph dashboard集成Grafana禁用SSL验证</div><div><br/></div><div>      <span style="font-weight: bold;">$ ceph dashboard set-grafana-api-url</span> <a href="http://ceph-admin.lab.example.com:3000/" style="font-weight: bold;">http://10.197.11.192:3000</a></div><div>      # Ceph dashboard集成Grafana</div><div>      # <span style="font-weight: bold;">该URL必须使用IP地址，不可使用域名！</span></div><div><br/></div><div><span style="font-weight: bold;">配置Grafana与Prometheus对接：</span></div><ul><li><div>访问URL <a href="http://ceph-admin.lab.example.com:3000/">http://ceph-admin.lab.example.com:3000</a>，并登陆Grafana界面。</div></li><li><div>点击&quot;Configuration&quot;，选择&quot;Data Sources&quot;。</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [25].png" type="image/png" data-filename="Image.png" width="117"/></div><div><br/></div><ul><li><div>点击&quot;Add data source&quot;添加数据源</div></li><li><div>数据源类型选择&quot;Prometheus&quot;</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [26].png" type="image/png" data-filename="Image.png" width="577"/></div><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [27].png" type="image/png" data-filename="Image.png" width="577"/></div><div><br/></div><ul><li><div>输入数据源自定义名称与IP地址</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [28].png" type="image/png" data-filename="Image.png" width="498"/></div><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [29].png" type="image/png" data-filename="Image.png" width="275"/></div><div><br/></div><ul><li><div>配置完成</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [30].png" type="image/png" data-filename="Image.png" width="577"/></div><div><br/></div><div><span style="font-weight: bold;">配置Grafana模板：</span></div><ul><li><div>Grafana模板可使用以下两种方式导入：</div></li></ul><div>     1. GitHub仓库：</div><div>        <a href="https://github.com/ceph/ceph/tree/master/monitoring/grafana/dashboards">https://github.com/ceph/ceph/tree/master/monitoring/grafana/dashboards</a></div><div>     2. ceph-grafana-dashboards软件包：</div><div>        <span style="font-weight: bold;">$ rpm -ql ceph-grafana-dashboards | grep json</span></div><div>        <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/ceph-dashboard-grafana模板.JPG" type="image/jpeg" data-filename="ceph-dashboard-grafana模板.JPG" width="554"/></div><ul><li><div><span style="font-weight: bold;">Grafana模板使用JSON数据格式。</span></div></li></ul><div><br/></div><ul><li><div>打开Grafana界面，点击&quot;+&quot;。</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [31].png" type="image/png" data-filename="Image.png" width="161"/></div><div><br/></div><ul><li><div>点击&quot;import&quot;，导入新的Grafana模板。</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [32].png" type="image/png" data-filename="Image.png" width="579"/></div><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [33].png" type="image/png" data-filename="Image.png" width="578"/></div><div><br/></div><ul><li><div>导入所有的Grafana被dashboard支持的模板文件，查看已导入的模板文件。</div></li></ul></div><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [34].png" type="image/png" data-filename="Image.png" width="577"/></div><div><br/></div><ul><li><div>查看Grafana模板详细信息，此处显示&quot;Ceph-Cluster&quot;模板的详细信息。</div></li><li><div>查看Ceph dashboard集成Grafana的监控界面。</div></li></ul><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [35].png" type="image/png" data-filename="Image.png" width="578"/></div><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [36].png" type="image/png" data-filename="Image.png" width="577"/></div><div>     <img src="Ceph Nautilus全功能集群部署与Dashboard集成_files/Image [37].png" type="image/png" data-filename="Image.png" width="577"/></div></div><div><br/></div><div><br/></div><div><br/></div></span>
</div></body></html> 