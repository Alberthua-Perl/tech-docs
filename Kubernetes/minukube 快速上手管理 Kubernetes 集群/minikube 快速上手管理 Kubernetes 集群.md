# minikube å¿«é€Ÿä¸Šæ‰‹ç®¡ç† Kubernetes é›†ç¾¤

## æ–‡æ¡£è¯´æ˜

æœ¬æ–‡ä¸»è¦ä»‹ç»å¦‚ä½•ä½¿ç”¨ minikube å¿«é€Ÿéƒ¨ç½²ä¸ç®¡ç†å•ä¸ªæ§åˆ¶èŠ‚ç‚¹ä¸é«˜å¯ç”¨çš„ Kubernetes é›†ç¾¤ï¼Œå¯æå¤§åœ°æ–¹ä¾¿åœ¨æœ¬åœ°åšå¼€å‘ä¸æµ‹è¯•ã€‚åŒæ—¶ï¼Œæœ¬åœ°éƒ¨ç½²è¿˜æ”¯æŒ `kvm`ã€`docker`ï¼ˆæ¨èï¼‰ä¸ `podman`ï¼ˆå®éªŒæ€§ï¼‰ç­‰é©±åŠ¨ï¼Œæ›´åŠ æ–¹ä¾¿åœ°å¿«é€Ÿéƒ¨ç½²é›†ç¾¤ã€‚minikube éƒ¨ç½²è¿˜æ”¯æŒä¸åŒçš„ `CNI` æ’ä»¶ï¼Œå¯åœ¨æœ¬åœ°ä½¿ç”¨ä¸åŒçš„æ’ä»¶è¿›è¡Œè°ƒè¯•ã€‚

æ­¤æ¬¡å®éªŒä¸­ï¼Œç¬”è€…åˆ†åˆ«ä½¿ç”¨ `flannel`ã€`cilium` æ’ä»¶éƒ¨ç½²äºå•ä¸ªæ§åˆ¶èŠ‚ç‚¹çš„ Kubernetes é›†ç¾¤ä¸­ï¼Œè€Œä½¿ç”¨ `calico` æ’ä»¶éƒ¨ç½²äº3ä¸ªæ§åˆ¶èŠ‚ç‚¹çš„é«˜å¯ç”¨é›†ç¾¤ä¸­ã€‚

å®éªŒç¯å¢ƒè¯´æ˜ï¼š

- æ“ä½œç³»ç»Ÿç±»å‹ï¼šRed Hat Enterprise Linux release 8.4 (Ootpa)
- CPU èµ„æºï¼š8 æ ¸å¿ƒ
- Memory èµ„æºï¼š32GiB
  > æ³¨æ„ï¼šæ ¹æ®å®é™…å¯ç”¨èµ„æºæ¥å®šï¼Œå»ºè®®æœ€ä½åˆ†é… 16GiB å†…å­˜ã€‚æ­¤æ¬¡å®éªŒä¸­ç”±äºè¦éƒ¨ç½²å¤šå¥—é›†ç¾¤ï¼Œå› æ­¤ç»™å®š 32GiB å†…å­˜ã€‚
- Docker ç‰ˆæœ¬ï¼š26.1.3
- [minikube ç‰ˆæœ¬](https://github.com/kubernetes/minikube/releases/download/v1.34.0/minikube-linux-amd64)ï¼šv1.34.0
- [docker-machine-driver-kvm2 ç‰ˆæœ¬](https://github.com/kubernetes/minikube/releases/download/v1.34.0/docker-machine-driver-kvm2-amd64)ï¼šv1.34.2

ğŸ’¥ å­˜åœ¨çš„é—®é¢˜ï¼šminikube éƒ¨ç½² Kubernetes é›†ç¾¤çš„éº»çƒ¦ä¹‹å¤„åœ¨äºå¯¹ `docker.io` ä¸ `gcr.io` ç­‰å®¹å™¨é•œåƒç«™ç‚¹çš„è®¿é—®ï¼ˆç½‘ç»œè®¿é—®é—®é¢˜ï¼‰ã€‚è™½ç„¶åœ¨ `minikube start` çš„é€‰é¡¹ä¸­æä¾› `--image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers`ï¼Œä½†æ˜¯åœ¨èŠ‚ç‚¹å¯åŠ¨åéƒ¨åˆ†ç»„ä»¶ï¼ˆå¦‚ flannel/calico/cilium ç­‰ï¼‰ä¾ç„¶éœ€è¦ä» docker.io æˆ– gcr.io ä¸­æ‹‰å–ï¼Œè‹¥è¶…æ—¶å§‹ç»ˆæ‹‰å–ä¸åˆ°ç›¸åº”çš„å®¹å™¨é•œåƒï¼Œé‚£ä¹ˆå°†å¯¼è‡´é›†ç¾¤ `NotReady`ã€‚å› æ­¤ï¼Œè§£å†³å®¹å™¨é•œåƒç«™ç‚¹çš„è®¿é—®é—®é¢˜å¯æœ‰æ•ˆè§£å†³ minikube éƒ¨ç½²å¤±è´¥ã€‚

ğŸ’ª å¯é€‰æ–¹æ¡ˆï¼šæ­¤æ¬¡å®éªŒä½¿ç”¨å±€åŸŸç½‘å†… `NanoPi R2S è½¯è·¯ç”±` å®ç°å¯¹å¤–éƒ¨å®¹å™¨é•œåƒä»“åº“çš„è®¿é—®ï¼Œè¿™æ ·åœ¨åç»­éƒ¨ç½²è¿‡ç¨‹ä¸­å¯ä¿è¯éƒ¨ç½²çš„æˆåŠŸç‡ã€‚

## æ–‡æ¡£ç›®å½•

- [Docker å®¹å™¨è¿è¡Œç¯å¢ƒå‡†å¤‡](#docker-å®¹å™¨è¿è¡Œç¯å¢ƒå‡†å¤‡)
  - [é…ç½® docker-ce.repo è½¯ä»¶æº](#é…ç½®-docker-cerepo-è½¯ä»¶æº)
  - [éƒ¨ç½² docker-ce ç»„ä»¶](#éƒ¨ç½²-docker-ce-ç»„ä»¶)
- [minikube ç›¸å…³ç»„ä»¶å‡†å¤‡](#minikube-ç›¸å…³ç»„ä»¶å‡†å¤‡)
  - [minikube ä¸‹è½½ä¸å®‰è£…](#minikube-ä¸‹è½½ä¸å®‰è£…)
  - [docker-machine-driver-kvm2 é©±åŠ¨ä¸‹è½½ä¸å®‰è£…](#docker-machine-driver-kvm2-é©±åŠ¨ä¸‹è½½ä¸å®‰è£…)
- [minikube å¿«é€Ÿéƒ¨ç½²å•ä¸ªæ§åˆ¶èŠ‚ç‚¹çš„ Kubernetes é›†ç¾¤](#minikube-å¿«é€Ÿéƒ¨ç½²å•ä¸ªæ§åˆ¶èŠ‚ç‚¹çš„-kubernetes-é›†ç¾¤)
  - [éƒ¨ç½²ä½¿ç”¨ Flannel CNI çš„é›†ç¾¤](#éƒ¨ç½²ä½¿ç”¨-flannel-cni-çš„é›†ç¾¤)
  - [éƒ¨ç½²ä½¿ç”¨ Cilium CNI çš„é›†ç¾¤](#éƒ¨ç½²ä½¿ç”¨-cilium-cni-çš„é›†ç¾¤)
- [minikube å¿«é€Ÿéƒ¨ç½²é«˜å¯ç”¨ Kubernetes é›†ç¾¤](#minikube-å¿«é€Ÿéƒ¨ç½²é«˜å¯ç”¨-kubernetes-é›†ç¾¤)
- [éƒ¨ç½²ä¸­çš„æ•…éšœæ’é™¤](#éƒ¨ç½²ä¸­çš„æ•…éšœæ’é™¤)
  - [æ·»åŠ èŠ‚ç‚¹å¤±è´¥æŠ¥é”™](#æ·»åŠ èŠ‚ç‚¹å¤±è´¥æŠ¥é”™)
  - [åˆ é™¤èŠ‚ç‚¹æŠ¥é”™](#åˆ é™¤èŠ‚ç‚¹æŠ¥é”™)
- [minikube ç›¸å…³å­å‘½ä»¤ä½¿ç”¨](#minikube-ç›¸å…³å­å‘½ä»¤ä½¿ç”¨)  
- [å‚è€ƒé“¾æ¥](#å‚è€ƒé“¾æ¥)  

## Docker å®¹å™¨è¿è¡Œç¯å¢ƒå‡†å¤‡

æ­¤æ¬¡å®éªŒä¸­ä½¿ç”¨ RHEL8 è¿è¡Œ minikubeï¼Œä½†åœ¨ RHEL8 ä¸­åº•å±‚é»˜è®¤ä½¿ç”¨ Podman ä½œä¸ºå®¹å™¨è¿è¡Œæ—¶ã€‚å› æ­¤ï¼Œåœ¨å®‰è£… Docker å®¹å™¨è¿è¡Œç¯å¢ƒä¹‹å‰éœ€åˆ é™¤ podman ç›¸å…³ç»„ä»¶ï¼ŒåŒ…æ‹¬ podmanã€buildah ç­‰ã€‚ç„¶åï¼Œå†ç¼–è¾‘ `/etc/yum.repos.d/docker-ce.repo` è½¯ä»¶æºæ–‡ä»¶ç”¨ä»¥å®‰è£… Docker-CE ç›¸å…³ç»„ä»¶ã€‚

### é…ç½® docker-ce.repo è½¯ä»¶æº

```plaintext
# RHEL8 ä¸­éƒ¨ç½² Docker-CE ç»„ä»¶
[docker-ce-stable]
name=Docker CE Stable - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/stable
enabled=1
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-stable-debuginfo]
name=Docker CE Stable - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/stable
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-stable-source]
name=Docker CE Stable - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/stable
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test]
name=Docker CE Test - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test-debuginfo]
name=Docker CE Test - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-test-source]
name=Docker CE Test - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/test
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly]
name=Docker CE Nightly - $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/$basearch/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly-debuginfo]
name=Docker CE Nightly - Debuginfo $basearch
baseurl=https://download.docker.com/linux/centos/$releasever/debug-$basearch/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg

[docker-ce-nightly-source]
name=Docker CE Nightly - Sources
baseurl=https://download.docker.com/linux/centos/$releasever/source/nightly
enabled=0
gpgcheck=1
gpgkey=https://download.docker.com/linux/centos/gpg
```

### éƒ¨ç½² docker-ce ç»„ä»¶

```bash
$ sudo rpm -qa | egrep "podman|buildah"  #1
$ sudo dnf remove -y podman buildah  #2
# å¯é€‰æ­¥éª¤ï¼ˆ#1ä¸#2ï¼‰ï¼šè‹¥æŸ¥è¯¢å‘ç°å·²å®‰è£… podman ä¸ buildahï¼Œé‚£ä¹ˆéœ€æ‰§è¡Œæ­¤æ­¥ç”¨ä»¥ç§»é™¤è¿™äº›ç»„ä»¶ã€‚

$ sudo dnf install -y docker-ce containerd.io docker-ce-cli
# å®‰è£… docker ä¸ containerd ç›¸å…³è½¯ä»¶åŒ…
$ sudo usermod -aG docker $USER
# å°†å½“å‰ç”¨æˆ·æ·»åŠ è¿› docker ç”¨æˆ·ç»„ï¼Œè¯¥ç”¨æˆ·å¯ç›´æ¥è°ƒç”¨ docker å‘½ä»¤ã€‚
$ sudo systemctl enable --now docker.service  #åŠ¡å¿…å¯åŠ¨ docker å®ˆæŠ¤è¿›ç¨‹ï¼Œå¦åˆ™ minikube éƒ¨ç½²é›†ç¾¤æ—¶æŠ¥é”™ï¼
$ docker version  #éªŒè¯å½“å‰ç”¨æˆ·æƒé™
```

## minikube ç›¸å…³ç»„ä»¶å‡†å¤‡

### minikube ä¸‹è½½ä¸å®‰è£…

```bash
wget https://github.com/kubernetes/minikube/releases/download/v1.34.0/minikube-linux-amd64
sudo cp ./minikube-linux-amd64 /usr/local/bin/minikube
```

### docker-machine-driver-kvm2 é©±åŠ¨ä¸‹è½½ä¸å®‰è£…

```bash
wget https://github.com/kubernetes/minikube/releases/download/v1.34.0/docker-machine-driver-kvm2-amd64
sudo cp ./docker-machine-driver-kvm2-amd64 /usr/local/bin/docker-machine-driver-kvm2
```

## minikube å¿«é€Ÿéƒ¨ç½²å•ä¸ªæ§åˆ¶èŠ‚ç‚¹çš„ Kubernetes é›†ç¾¤

æ­¤å¤„ä»¥ `flannel` ä¸ `cilium` CNI æ’ä»¶ä¸ºä¾‹éƒ¨ç½²å•ä¸ªæ§åˆ¶èŠ‚ç‚¹çš„é›†ç¾¤ã€‚

### éƒ¨ç½²ä½¿ç”¨ Flannel CNI çš„é›†ç¾¤

ğŸ§ª ç›´æ¥æŒ‡å®š3ä¸ªèŠ‚ç‚¹éƒ¨ç½²é›†ç¾¤ï¼š

```bash
$ minikube start --nodes=3 --profile=flannel-aio \
    --cni=flannel --container-runtime=cri-o --driver=docker \
    --kubernetes-version=v1.31.0 --memory=4096m
# ç›´æ¥æŒ‡å®š3ä¸ªèŠ‚ç‚¹ï¼ˆé»˜è®¤1ä¸ªæ§åˆ¶èŠ‚ç‚¹ä¸2ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼‰å¯åŠ¨é›†ç¾¤ã€‚æ­¤å¤„ä½¿ç”¨ docker é©±åŠ¨ï¼Œå› æ­¤ï¼ŒèŠ‚ç‚¹ä»¥å®¹å™¨çš„æ–¹å¼è¿è¡Œã€‚

# å„é€‰é¡¹è¯´æ˜ï¼š
#   --nodesï¼šæŒ‡å®šéƒ¨ç½²çš„èŠ‚ç‚¹æ•°é‡
#   --profileï¼šæŒ‡å®šéƒ¨ç½²é›†ç¾¤çš„æ¦‚è§ˆåç§°
#   --cniï¼šæŒ‡å®š CNI å®¹å™¨ç½‘ç»œæ¥å£æ’ä»¶ï¼ŒåŒ…æ‹¬ auto, bridge, calico, cilium, flannel, kindnet æˆ– CNI manifest (é»˜è®¤ä¸º auto)ã€‚
#   --container-runtimeï¼šæŒ‡å®šé›†ç¾¤ä¸­å®¹å™¨è¿è¡Œæ—¶ï¼ŒåŒ…æ‹¬ docker, cri-o, containerd (é»˜è®¤ä¸º auto)ã€‚
#   --driverï¼šæŒ‡å®šè¿è¡Œé›†ç¾¤èŠ‚ç‚¹çš„é©±åŠ¨ï¼ŒåŒ…æ‹¬ virtualbox, kvm2, qemu2, qemu, vmware, none, docker, podman, ssh (é»˜è®¤ä¸º auto-detect)ã€‚è¯¥é©±åŠ¨ä¸ºé›†ç¾¤èŠ‚ç‚¹ä»¥ä½•ç§æ–¹å¼è¿è¡Œï¼Œè‹¥é©±åŠ¨ä¸º dockerï¼Œé‚£ä¹ˆé›†ç¾¤èŠ‚ç‚¹ä»¥å®¹å™¨æ–¹å¼è¿è¡Œï¼Œè‹¥é©±åŠ¨ä¸º kvm2ï¼Œé‚£ä¹ˆé›†ç¾¤èŠ‚ç‚¹ä»¥ kvm è™šæ‹Ÿæœºçš„æ–¹å¼è¿è¡Œã€‚
#   --kubernetes-versionï¼šæŒ‡å®šéƒ¨ç½²çš„é›†ç¾¤ç‰ˆæœ¬
#   --memoryï¼šæŒ‡å®šé›†ç¾¤èŠ‚ç‚¹é™åˆ¶çš„å¯ä½¿ç”¨å†…å­˜å®¹é‡

$ minikube kubectl --profile=flannel-aio -- get pods -A -o wide
NAMESPACE      NAME                                  READY   STATUS    RESTARTS   AGE   IP             NODE              NOMINATED NODE   READINESS GATES
kube-flannel   kube-flannel-ds-jfdcz                 1/1     Running   0          9h    192.168.76.2   flannel-aio       <none>           <none>
kube-flannel   kube-flannel-ds-wfwq8                 1/1     Running   0          9h    192.168.76.4   flannel-aio-m03   <none>           <none>
kube-flannel   kube-flannel-ds-zx8tl                 1/1     Running   0          9h    192.168.76.3   flannel-aio-m02   <none>           <none>
kube-system    coredns-6f6b679f8f-rxp4s              1/1     Running   0          9h    10.244.2.2     flannel-aio-m03   <none>           <none>
kube-system    etcd-flannel-aio                      1/1     Running   0          9h    192.168.76.2   flannel-aio       <none>           <none>
kube-system    kube-apiserver-flannel-aio            1/1     Running   0          9h    192.168.76.2   flannel-aio       <none>           <none>
kube-system    kube-controller-manager-flannel-aio   1/1     Running   0          9h    192.168.76.2   flannel-aio       <none>           <none>
kube-system    kube-proxy-9l2jb                      1/1     Running   0          9h    192.168.76.2   flannel-aio       <none>           <none>
kube-system    kube-proxy-glgxz                      1/1     Running   0          9h    192.168.76.4   flannel-aio-m03   <none>           <none>
kube-system    kube-proxy-n2v96                      1/1     Running   0          9h    192.168.76.3   flannel-aio-m02   <none>           <none>
kube-system    kube-scheduler-flannel-aio            1/1     Running   0          9h    192.168.76.2   flannel-aio       <none>           <none>
kube-system    storage-provisioner                   1/1     Running   0          9h    192.168.76.4   flannel-aio-m03   <none>           <none>
# ç­‰å¾… flannel pod çŠ¶æ€è½¬å˜ä¸º Running åï¼Œcoredns pod çŠ¶æ€ä¹Ÿå°†è½¬å˜ä¸º Runningï¼Œé›†ç¾¤çŠ¶æ€æœ€åä» NotReady è½¬å˜ä¸º Readyã€‚

$ minikube kubectl --profile=flannel-aio -- get nodes
NAME              STATUS   ROLES           AGE   VERSION
flannel-aio       Ready    control-plane   9h    v1.31.0
flannel-aio-m02   Ready    <none>          9h    v1.31.0
flannel-aio-m03   Ready    <none>          9h    v1.31.0

### å¯é€‰æ­¥éª¤ï¼š#1ã€#2ã€#3
$ echo "alias k-aio-flannel='minikube kubectl --profile=flannel-aio --'" >> ~/.bash_profile  #1
# ä¸ºäº†æ›´åŠ ä¾¿æ·åœ°æŸ¥è¯¢é›†ç¾¤çŠ¶æ€ï¼Œå¯æ·»åŠ ä»¥ä¸Šå‘½ä»¤è¡Œåˆ«åã€‚
$ k-aio-flannel get nodes  #2
$ k-aio-flannel get pods -A -o wide  #3
```

### éƒ¨ç½²ä½¿ç”¨ Cilium CNI çš„é›†ç¾¤

ğŸ§ª å…ˆéƒ¨ç½²å•ä¸ªæ§åˆ¶èŠ‚ç‚¹ï¼Œå†æ·»åŠ 2ä¸ªå·¥ä½œèŠ‚ç‚¹å®Œæˆé›†ç¾¤éƒ¨ç½²ï¼š

```bash
$ minikube start --profile=cilium-aio \
    --cni=cilium --container-runtime=cri-o --driver=docker \
    --kubernetes-version=v1.31.0 --memory=4096m
# æœªæŒ‡å®š --nodes é€‰é¡¹çš„è¯å°†ç›´æ¥éƒ¨ç½²å•èŠ‚ç‚¹é›†ç¾¤ï¼Œè¯¥èŠ‚ç‚¹ä½œä¸ºæ§åˆ¶èŠ‚ç‚¹è¿è¡Œï¼Œåç»­æ‰©å±•é›†ç¾¤è§„æ¨¡å¯å†æ·»åŠ èŠ‚ç‚¹å³å¯ã€‚

$ minikube node add --profile=cilium-aio --worker=true
# æ·»åŠ å·¥ä½œèŠ‚ç‚¹æ—¶ï¼Œminikube ä¸ºæ–°æ·»åŠ çš„èŠ‚ç‚¹è‡ªåŠ¨æŒ‰ç…§é¡ºåºå‘½åã€‚
# è‹¥æˆåŠŸæ·»åŠ èŠ‚ç‚¹ï¼Œå¯ç»§ç»­æ‰§è¡Œä»¥ä¸Šå‘½ä»¤æ·»åŠ åç»­èŠ‚ç‚¹ã€‚

#ä»¥æ·»åŠ 2ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸ºä¾‹
$ minikube kubectl --profile=cilium-aio -- get pods -A -o wide                                                          
NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE   IP             NODE             NOMINATED NODE   READINESS GATES
kube-system   cilium-56jqq                         1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>
kube-system   cilium-6s5jd                         1/1     Running   0          22h   192.168.67.4   cilium-aio-m03   <none>           <none>
kube-system   cilium-envoy-fc6rx                   1/1     Running   0          22h   192.168.67.3   cilium-aio-m02   <none>           <none>
kube-system   cilium-envoy-kb4k8                   1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>
kube-system   cilium-envoy-n498s                   1/1     Running   0          22h   192.168.67.4   cilium-aio-m03   <none>           <none>
kube-system   cilium-fp2mk                         1/1     Running   0          22h   192.168.67.3   cilium-aio-m02   <none>           <none>
kube-system   cilium-operator-5c7867ccd5-fm692     1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>
kube-system   coredns-6f6b679f8f-swvxg             1/1     Running   0          22h   10.244.0.170   cilium-aio       <none>           <none>
kube-system   etcd-cilium-aio                      1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>
kube-system   kube-apiserver-cilium-aio            1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>
kube-system   kube-controller-manager-cilium-aio   1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>
kube-system   kube-proxy-c52h4                     1/1     Running   0          22h   192.168.67.3   cilium-aio-m02   <none>           <none>
kube-system   kube-proxy-l78cx                     1/1     Running   0          22h   192.168.67.4   cilium-aio-m03   <none>           <none>
kube-system   kube-proxy-nqbm4                     1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>
kube-system   kube-scheduler-cilium-aio            1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>
kube-system   storage-provisioner                  1/1     Running   0          22h   192.168.67.2   cilium-aio       <none>           <none>

$ minikube kubectl --profile=cilium-aio -- get nodes
NAME             STATUS   ROLES           AGE   VERSION
cilium-aio       Ready    control-plane   22h   v1.31.0
cilium-aio-m02   Ready    <none>          22h   v1.31.0
cilium-aio-m03   Ready    <none>          22h   v1.31.0

### å¯é€‰æ­¥éª¤ï¼š#1ã€#2ã€#3
$ echo "alias k-aio-cilium='minikube kubectl --profile=cilium-aio --'" >> ~/.bash_profile  #1
# ä¸ºäº†æ›´åŠ ä¾¿æ·åœ°æŸ¥è¯¢é›†ç¾¤çŠ¶æ€ï¼Œå¯æ·»åŠ ä»¥ä¸Šå‘½ä»¤è¡Œåˆ«åã€‚
$ k-aio-cilium get nodes  #2
$ k-aio-cilium get pods -A -o wide  #3
```

## minikube å¿«é€Ÿéƒ¨ç½²é«˜å¯ç”¨ Kubernetes é›†ç¾¤

ğŸ§ª å…ˆåˆå§‹åŒ– 3 ä¸ªæ§åˆ¶èŠ‚ç‚¹ï¼ˆcontrol-planeï¼‰çš„é«˜å¯ç”¨é›†ç¾¤ï¼š

```bash
$ minikube start --profile=ha-multi-nodes --nodes=3 --ha=true \
    --apiserver-port=6443 --cni=calico --container-runtime=cri-o --driver=docker \
    --kubernetes-version=v1.31.0 --memory=4096m
ğŸ˜„  [ha-multi-nodes] minikube v1.34.0 on Redhat 8.4
âœ¨  Using the docker driver based on user configuration
ğŸ“Œ  Using Docker driver with root privileges
ğŸ‘  Starting "ha-multi-nodes" primary control-plane node in "ha-multi-nodes" cluster
ğŸšœ  Pulling base image v0.0.45 ...
ğŸ”¥  Creating docker container (CPUs=2, Memory=4096MB) ...
ğŸŒ  Found network options:
    â–ª NO_PROXY=192.168.0.0/16,10.96.0.0/12
ğŸ  Preparing Kubernetes v1.31.0 on CRI-O 1.24.6 ...
    â–ª env NO_PROXY=192.168.0.0/16,10.96.0.0/12
    â–ª Generating certificates and keys ...
    â–ª Booting up control plane ...
    â–ª Configuring RBAC rules ...
ğŸ”—  Configuring Calico (Container Networking Interface) ...
    â–ª Using image gcr.io/k8s-minikube/storage-provisioner:v5
ğŸŒŸ  Enabled addons: storage-provisioner, default-storageclass

ğŸ‘  Starting "ha-multi-nodes-m02" control-plane node in "ha-multi-nodes" cluster
ğŸšœ  Pulling base image v0.0.45 ...
ğŸ”¥  Creating docker container (CPUs=2, Memory=4096MB) ...
ğŸŒ  Found network options:
    â–ª NO_PROXY=192.168.0.0/16,10.96.0.0/12
ğŸ  Preparing Kubernetes v1.31.0 on CRI-O 1.24.6 ...
    â–ª env NO_PROXY=192.168.0.0/16,10.96.0.0/12
ğŸ”  Verifying Kubernetes components...

ğŸšœ  Pulling base image v0.0.45 ...
ğŸ”¥  Creating docker container (CPUs=2, Memory=4096MB) ...
ğŸŒ  Found network options:
    â–ª NO_PROXY=192.168.0.0/16,10.96.0.0/12
ğŸ  Preparing Kubernetes v1.31.0 on CRI-O 1.24.6 ...
    â–ª env NO_PROXY=192.168.0.0/16,10.96.0.0/12
ğŸ”  Verifying Kubernetes components...
ğŸ’¡  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
ğŸ„  Done! kubectl is now configured to use "ha-multi-nodes" cluster and "default" namespace by default

$ minikube kubectl --profile=ha-multi-nodes -- get pods -A
# ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œcalico-node pod çŠ¶æ€è½¬å˜ä¸º Running åï¼Œæ•´ä¸ªé›†ç¾¤çš„ node çŠ¶æ€è½¬å˜ä¸º Readyã€‚

$ minikube kubectl --profile=ha-multi-nodes -- get nodes
NAME                 STATUS     ROLES           AGE   VERSION
ha-multi-nodes       Ready      control-plane   12h   v1.31.0
ha-multi-nodes-m02   Ready      control-plane   12h   v1.31.0
ha-multi-nodes-m03   Ready      control-plane   12h   v1.31.0
```

æ·»åŠ æ–°çš„èŠ‚ç‚¹ä»¥æ‰©å±•é›†ç¾¤è§„æ¨¡ï¼š

```bash
$ minikube node add --profile=ha-multi-nodes --worker=true
# æ·»åŠ å·¥ä½œèŠ‚ç‚¹æ—¶ï¼Œminikube ä¸ºæ–°æ·»åŠ çš„èŠ‚ç‚¹è‡ªåŠ¨æŒ‰ç…§é¡ºåºå‘½åã€‚
# è‹¥æˆåŠŸæ·»åŠ èŠ‚ç‚¹ï¼Œå¯ç»§ç»­æ‰§è¡Œä»¥ä¸Šå‘½ä»¤æ·»åŠ åç»­èŠ‚ç‚¹ã€‚

#ä»¥æ·»åŠ 3ä¸ªå·¥ä½œèŠ‚ç‚¹ä¸ºä¾‹ï¼š3 master-nodes + 3 worker-nodes
$ minikube kubectl --profile=ha-multi-nodes -- get pods -A                                                              
NAMESPACE       NAME                                          READY   STATUS    RESTARTS        AGE
app-predeploy   golang-codeready-workspace-75c4b6869d-bgqjc   1/1     Running   2               25h
kube-system     calico-kube-controllers-7fbd86d5c5-9bhgc      1/1     Running   2               38h
kube-system     calico-node-64d59                             1/1     Running   2               38h
kube-system     calico-node-75gtl                             1/1     Running   1               22h
kube-system     calico-node-9kvkk                             1/1     Running   1               22h
kube-system     calico-node-f7q8c                             1/1     Running   1               24h
kube-system     calico-node-jmkr9                             1/1     Running   4 (6m ago)      38h
kube-system     calico-node-x9h52                             1/1     Running   2               38h
kube-system     coredns-6f6b679f8f-7rspv                      1/1     Running   2               38h
kube-system     coredns-6f6b679f8f-lx4g5                      1/1     Running   2               38h
kube-system     etcd-ha-multi-nodes                           1/1     Running   2               38h
kube-system     etcd-ha-multi-nodes-m02                       1/1     Running   6 (6m36s ago)   38h
kube-system     etcd-ha-multi-nodes-m03                       1/1     Running   6 (6m2s ago)    38h
kube-system     kube-apiserver-ha-multi-nodes                 1/1     Running   4 (6m18s ago)   38h
kube-system     kube-apiserver-ha-multi-nodes-m02             1/1     Running   6 (6m36s ago)   38h
kube-system     kube-apiserver-ha-multi-nodes-m03             1/1     Running   6 (6m3s ago)    38h
kube-system     kube-controller-manager-ha-multi-nodes        1/1     Running   4 (6m14s ago)   38h
kube-system     kube-controller-manager-ha-multi-nodes-m02    1/1     Running   7 (6m13s ago)   38h
kube-system     kube-controller-manager-ha-multi-nodes-m03    1/1     Running   6 (6m3s ago)    38h
kube-system     kube-proxy-2ggbj                              1/1     Running   2               38h
kube-system     kube-proxy-4vzpw                              1/1     Running   1               22h
kube-system     kube-proxy-jq8fl                              1/1     Running   2               38h
kube-system     kube-proxy-lnmgm                              1/1     Running   1               22h
kube-system     kube-proxy-pds9w                              1/1     Running   1               24h
kube-system     kube-proxy-vgdcr                              1/1     Running   2               38h
kube-system     kube-scheduler-ha-multi-nodes                 1/1     Running   2               38h
kube-system     kube-scheduler-ha-multi-nodes-m02             1/1     Running   6 (6m36s ago)   38h
kube-system     kube-scheduler-ha-multi-nodes-m03             1/1     Running   6 (6m3s ago)    38h
kube-system     kube-vip-ha-multi-nodes                       1/1     Running   1               24h
kube-system     kube-vip-ha-multi-nodes-m02                   1/1     Running   6 (6m36s ago)   38h
kube-system     kube-vip-ha-multi-nodes-m03                   1/1     Running   6 (6m3s ago)    38h
kube-system     storage-provisioner                           1/1     Running   4               38h

$ minikube kubectl --profile=ha-multi-nodes -- get nodes                                                                
NAME                 STATUS   ROLES           AGE   VERSION
ha-multi-nodes       Ready    control-plane   38h   v1.31.0
ha-multi-nodes-m02   Ready    control-plane   38h   v1.31.0
ha-multi-nodes-m03   Ready    control-plane   38h   v1.31.0
ha-multi-nodes-m04   Ready    <none>          24h   v1.31.0
ha-multi-nodes-m08   Ready    <none>          22h   v1.31.0
ha-multi-nodes-m09   Ready    <none>          22h   v1.31.0

### å¯é€‰æ­¥éª¤ï¼š#1ã€#2ã€#3
$ echo "alias k-ha-calico='minikube kubectl --profile=ha-multi-nodes --'" >> ~/.bash_profile  #1
# ä¸ºäº†æ›´åŠ ä¾¿æ·åœ°æŸ¥è¯¢é›†ç¾¤çŠ¶æ€ï¼Œå¯æ·»åŠ ä»¥ä¸Šå‘½ä»¤è¡Œåˆ«åã€‚
$ k-ha-calico get nodes  #2
$ k-ha-calico get pods -A -o wide  #3
```

## æµ‹è¯•é«˜å¯ç”¨é›†ç¾¤åŠŸèƒ½

åœ¨ profile åä¸º ha-multi-nodes çš„é›†ç¾¤ä¸­ä½¿ç”¨ä»¥ä¸‹ [manifest](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/golang-codeready-workspace-deployment.yml) æ–‡ä»¶éƒ¨ç½² Golang workspace åº”ç”¨ï¼š

```bash
$ k-ha-calico create namespace app-predeploy
# åˆ›å»ºå‘½ä»¤ç©ºé—´ç”¨äºéƒ¨ç½²åº”ç”¨
$ vim golang-codeready-workspace-deployment.yml  #å¦‚ä¸‹æ‰€ç¤º
```

```yaml
# file: golang-codeready-workspace-deployment.yml
apiVersion: v1
kind: Service
metadata:
  labels:
    name: golang-codeready-workspace
  name: golang-codeready-workspace
  namespace: app-predeploy
spec:  
  ports:
    # the port that this service should serve on
    - port: 8080
      protocol: TCP
      targetPort: 8080
      nodePort: 30001
  # label keys and values that must match in order to receive traffic for this service
  selector:
    app: golang-codeready-workspace
  type: NodePort
  #type: ClusterIP
---    
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: golang-codeready-workspace
  name: golang-codeready-workspace
  namespace: app-predeploy
spec:  
  replicas: 1
  selector:
    matchLabels:
      app: golang-codeready-workspace
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: golang-codeready-workspace
    spec:
      containers:
      - image: quay.io/alberthua/golang-code-server:v1.1
        imagePullPolicy: IfNotPresent
        name: golang-codeready-workspace
        ports:
        - containerPort: 8080
          protocol: TCP
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
```

```bash
$ k-ha-calico apply -f ./golang-codeready-workspace-deployment.yml
$ k-ha-calico get all -n app-predeploy                                                                       
NAME                                              READY   STATUS    RESTARTS   AGE
pod/golang-codeready-workspace-75c4b6869d-bgqjc   1/1     Running   2          30h

NAME                                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
service/golang-codeready-workspace   NodePort   10.98.169.101   <none>        8080:30001/TCP   30h

NAME                                         READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/golang-codeready-workspace   1/1     1            1           30h

NAME                                                    DESIRED   CURRENT   READY   AGE
replicaset.apps/golang-codeready-workspace-75c4b6869d   1         1         1       30h
$ k-ha-calico get nodes -o wide | awk '{print $1"\t"$2"\t"$3"\t"$6}'                                         
NAME                STATUS  ROLES           INTERNAL-IP
ha-multi-nodes      Ready   control-plane   192.168.58.2
ha-multi-nodes-m02  Ready   control-plane   192.168.58.3
ha-multi-nodes-m03  Ready   control-plane   192.168.58.4
ha-multi-nodes-m04  Ready   <none>          192.168.58.5
ha-multi-nodes-m08  Ready   <none>          192.168.58.9
ha-multi-nodes-m09  Ready   <none>          192.168.58.10
```

åœ¨æœ¬åœ°èŠ‚ç‚¹ä¸Šæ‰“å¼€æµè§ˆå™¨ï¼ˆæ¨è Chromeï¼‰ä½¿ç”¨ä»¥ä¸Šä»»æ„ä¸€ä¸ªå·¥ä½œèŠ‚ç‚¹çš„ IPv4 åœ°å€ä¸ 30001 ç«¯å£è®¿é—®æ­¤åº”ç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![minikube-ha-calico-golang-workspace-demo](images/minikube-ha-calico-golang-workspace-demo.png)

golang-workspace åº”ç”¨å¯åŠ¨åï¼Œå³å¯ä½¿ç”¨æ­¤ workspace è¿›è¡Œä»£ç æ‹‰å–ä¸å¼€å‘æµ‹è¯•å·¥ä½œã€‚

## éƒ¨ç½²ä¸­çš„æ•…éšœæ’é™¤

### æ·»åŠ èŠ‚ç‚¹å¤±è´¥æŠ¥é”™

```bash
$ minikube node add --profile ha-multi-nodes --worker=true
ğŸ˜„  Adding node m06 to cluster ha-multi-nodes as [worker]
ğŸ‘  Starting "ha-multi-nodes-m06" worker node in "ha-multi-nodes" cluster
ğŸšœ  Pulling base image v0.0.45 ...
ğŸ”¥  Creating docker container (CPUs=2, Memory=4096MB) ...
âœ‹  Stopping node "ha-multi-nodes-m06"  ...
ğŸ›‘  Powering off "ha-multi-nodes-m06" via SSH ...
ğŸ”¥  Deleting "ha-multi-nodes-m06" in docker ...
ğŸ¤¦  StartHost failed, but will try again: creating host: create: provisioning: ssh command error:
command : sudo mkdir -p /etc/sysconfig && printf %s "
CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
" | sudo tee /etc/sysconfig/crio.minikube && sudo systemctl restart crio
err     : Process exited with status 1
output  :
CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
Job for crio.service failed because the control process exited with error code.
See "systemctl status crio.service" and "journalctl -xeu crio.service" for details.

...

âŒ  Exiting due to GUEST_NODE_ADD: failed to add node: Failed to start host: creating host: create: provisioning: ssh command error:
command : sudo mkdir -p /etc/sysconfig && printf %s "
CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
" | sudo tee /etc/sysconfig/crio.minikube && sudo systemctl restart crio
err     : Process exited with status 1
output  :
CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
Job for crio.service failed because the control process exited with error code.
See "systemctl status crio.service" and "journalctl -xeu crio.service" for details.


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                           â”‚
â”‚    ğŸ˜¿  If the above advice does not help, please let us know:                             â”‚
â”‚    ğŸ‘‰  https://github.com/kubernetes/minikube/issues/new/choose                           â”‚
â”‚                                                                                           â”‚
â”‚    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    â”‚
â”‚    Please also attach the following file to the GitHub issue:                             â”‚
â”‚    - /tmp/minikube_node_e51c5cbe511fcc5f9eb7e956570eb8b8d9a5f423_0.log                    â”‚
â”‚                                                                                           â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

è§£å†³æ–¹æ¡ˆï¼š

æŸ¥çœ‹ `systemctl status docker.service` å®ˆæŠ¤è¿›ç¨‹æ—¥å¿—ä¸­ï¼Œå‘ç°å¤§é‡çš„ `Too many open files` æŠ¥é”™ï¼Œå› æ­¤å¯æ›´æ–°ä»¥ä¸‹å†…æ ¸å‚æ•°è§£å†³ï¼š

```bash
$ sudo vim /etc/sysctl.d/10-container-limits.conf
fs.inotify.max_queued_events = 32768
fs.inotify.max_user_instances = 512
fs.inotify.max_user_watches = 524288

$ sudo sysctl --system
# æŒä¹…åŒ–æ›´æ–°å†…æ ¸å‚æ•°ä½¿å…¶ç”Ÿæ•ˆ
```

### åˆ é™¤èŠ‚ç‚¹æŠ¥é”™

ç”±äºèŠ‚ç‚¹ä¸­çš„ `kubelet` å®ˆæŠ¤è¿›ç¨‹ä¸º inactive çŠ¶æ€ï¼Œminikube æ— æ³•æ‰¾åˆ°èŠ‚ç‚¹è€Œå¯¼è‡´æ— æ³•åˆ é™¤èŠ‚ç‚¹ï¼š

```bash
$ minikube node delete --profile ha-multi-nodes ha-multi-nodes-m04
ğŸ”¥  Deleting node ha-multi-nodes-m04 from cluster ha-multi-nodes
E0509 09:43:10.643740 2016804 node.go:177] kubectl delete node "ha-multi-nodes-m04" failed: nodes "ha-multi-nodes-m04" not found

âŒ  Exiting due to GUEST_NODE_DELETE: deleting node: nodes "ha-multi-nodes-m04" not found

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                                                                           â”‚
â”‚    ğŸ˜¿  If the above advice does not help, please let us know:                             â”‚
â”‚    ğŸ‘‰  https://github.com/kubernetes/minikube/issues/new/choose                           â”‚
â”‚                                                                                           â”‚
â”‚    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    â”‚
â”‚    Please also attach the following file to the GitHub issue:                             â”‚
â”‚    - /tmp/minikube_node_ac9805ce5e5c1c617806039753a7a33917712c01_0.log                    â”‚
â”‚                                                                                           â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

æ— æ³•åˆ é™¤çš„èŠ‚ç‚¹å°†å§‹ç»ˆä¿ç•™åœ¨ profile ä¸­ï¼Œè‹¥æ–°æ·»åŠ çš„èŠ‚ç‚¹å°†é¡ºå»¶ç¼–å·ã€‚å› æ­¤ï¼Œæ— æ³•åˆ é™¤çš„èŠ‚ç‚¹å°†ç»§ç»­ä¿ç•™ï¼Œéœ€è¦æ·»åŠ æ–°èŠ‚ç‚¹æ—¶ï¼Œç»§ç»­æ‰§è¡Œ `minikube node add` å‘½ä»¤å³å¯ã€‚

```bash
$ minikube status --profile ha-multi-nodes
E0509 09:47:23.453502 2025488 status.go:263] The "ha-multi-nodes-m04" host does not exist!
E0509 09:47:23.453566 2025488 status.go:263] The "ha-multi-nodes-m05" host does not exist!
E0509 09:47:23.453607 2025488 status.go:263] The "ha-multi-nodes-m06" host does not exist!
...
ha-multi-nodes-m04
type: Worker
host: Nonexistent
kubelet: Nonexistent

ha-multi-nodes-m05
type: Worker
host: Nonexistent
kubelet: Nonexistent

ha-multi-nodes-m06
type: Worker
host: Nonexistent
kubelet: Nonexistent
```

## minikube ç›¸å…³å­å‘½ä»¤ä½¿ç”¨

æŸ¥çœ‹ minikube å‘½ä»¤çš„é€šç”¨é€‰é¡¹ï¼š

```bash
$ minikube options
```

æŸ¥çœ‹æœ¬åœ°çš„æ‰€æœ‰é›†ç¾¤ profileï¼š

```bash
$ minikube profile list
|----------------|-----------|---------|----------------|------|---------|---------|-------|----------------|--------------------|
|    Profile     | VM Driver | Runtime |       IP       | Port | Version | Status  | Nodes | Active Profile | Active Kubecontext |
|----------------|-----------|---------|----------------|------|---------|---------|-------|----------------|--------------------|
| cilium-aio     | docker    | crio    | 192.168.67.2   | 8443 | v1.31.0 | Running |     3 |                |                    |
| flannel-aio    | docker    | crio    | 192.168.76.2   | 8443 | v1.31.0 | Running |     3 |                |                    |
| ha-multi-nodes | docker    | crio    | 192.168.58.254 | 6443 | v1.31.0 | HAppy   |     7 |                | *                  |
|----------------|-----------|---------|----------------|------|---------|---------|-------|----------------|--------------------|
```

æŸ¥çœ‹æŒ‡å®šé›†ç¾¤ profile çš„çŠ¶æ€ï¼š

```bash
$ minikube [--profile=<name>] status
# è‹¥ä¸æŒ‡å®š profile åç§°ï¼Œåˆ™é»˜è®¤åä¸º minikube çš„ profileã€‚

$ minikube --profile=cilium-aio status
cilium-aio
type: Control Plane
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured

cilium-aio-m02
type: Worker
host: Running
kubelet: Running

cilium-aio-m03
type: Worker
host: Running
kubelet: Running
```

åœæ­¢æŒ‡å®šé›†ç¾¤ profile çš„èŠ‚ç‚¹ï¼š

```bash
$ minikube stop [--profile=<name>]

$ minikube stop --profile=ha-multi-nodes
âœ‹  Stopping node "ha-multi-nodes-m09"  ...
ğŸ›‘  Powering off "ha-multi-nodes-m09" via SSH ...
âœ‹  Stopping node "ha-multi-nodes-m08"  ...
ğŸ›‘  Powering off "ha-multi-nodes-m08" via SSH ...
âœ‹  Stopping node "ha-multi-nodes-m07"  ...
ğŸ›‘  Powering off "ha-multi-nodes-m07" via SSH ...
âœ‹  Stopping node "ha-multi-nodes-m04"  ...
ğŸ›‘  Powering off "ha-multi-nodes-m04" via SSH ...
âœ‹  Stopping node "ha-multi-nodes-m03"  ...
ğŸ›‘  Powering off "ha-multi-nodes-m03" via SSH ...
âœ‹  Stopping node "ha-multi-nodes-m02"  ...
ğŸ›‘  Powering off "ha-multi-nodes-m02" via SSH ...
âœ‹  Stopping node "ha-multi-nodes"  ...
ğŸ›‘  Powering off "ha-multi-nodes" via SSH ...
ğŸ›‘  7 nodes stopped.
```

## å‚è€ƒé“¾æ¥

- â¤ [minikube | GitHub](https://github.com/kubernetes/minikube)
- [minikube releases | GitHub](https://github.com/kubernetes/minikube/releases)
- [minikube Docs](https://minikube.sigs.k8s.io/docs/)
- [ä½¿ç”¨å¤šæ§åˆ¶å¹³é¢ - é«˜å¯ç”¨é›†ç¾¤ | minikube Docs](https://minikube.kubernetes.ac.cn/docs/tutorials/multi_control_plane_ha_clusters/)
- [ä½¿ç”¨ Minikube å®‰è£… Kubernetes | Kubernetes Docs](https://people.wikimedia.org/~jayme/k8s-docs/v1.16/zh/docs/setup/learning-environment/minikube/)
